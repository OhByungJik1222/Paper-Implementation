{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOrigXbIlSAoHlMnuoDdUJN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"id":"54rlZ5vemFXb","executionInfo":{"status":"ok","timestamp":1770637282157,"user_tz":-540,"elapsed":4,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from torchsummary import summary\n","\n","from torch.utils import data\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["# ReLU 활성화 함수 (Section 3.1) - 학습 시간 단축\n","# LRN (Section 3.3) - 과적합 방지\n","# Overlapping Pooling (Section 3.4) - 과적합 방지\n","# Dropout (Section 4.2) - 과적합 방지\n","# Bias Initialization (Section 5) - ReLU 함수에 양의 입력 -> 초기 단계 학습 가속\n","class AlexNet(nn.Module):\n","    def __init__(self, num_classes=1000): # Section 3.5\n","        # 입력 크기: (b x 3 x 227 x 227)\n","        # 논문 상에선 입력 크기가 224라고 작성되어 있지만 실제론 227\n","        super().__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4), # (b x 96 x 55 x 55)\n","            nn.ReLU(), # Section 3.1\n","            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2), # Section 3.3\n","            nn.MaxPool2d(kernel_size=3, stride=2), # Section 3.4 (b x 96 x 27 x 27)\n","            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2), # (b x 256 x 27 x 27)\n","            nn.ReLU(),\n","            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n","            nn.MaxPool2d(kernel_size=3, stride=2), # (b x 256 x 13 x 13)\n","            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # (b x 384 x 13 x 13)\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1), # (b x 384 x 13 x 13)\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1), # (b x 256 x 13 x 13)\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2) # (b x 256 x 6 x 6)\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Dropout(p=0.5), # Section 4.2\n","            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(in_features=4096, out_features=4096),\n","            nn.ReLU(),\n","            nn.Linear(in_features=4096, out_features=num_classes)\n","        )\n","\n","        self.init_wb()\n","\n","    def init_wb(self): # Section 5\n","        for layer in self.conv:\n","            if isinstance(layer, nn.Conv2d):\n","                nn.init.normal_(layer.weight, mean=0, std=0.01)\n","                nn.init.constant_(layer.bias, 0)\n","\n","        nn.init.constant_(self.conv[4].bias, 1)\n","        nn.init.constant_(self.conv[10].bias, 1)\n","        nn.init.constant_(self.conv[12].bias, 1)\n","\n","        for layer in self.fc:\n","            if isinstance(layer, nn.Linear):\n","                nn.init.normal_(layer.weight, mean=0, std=0.01)\n","                nn.init.constant_(layer.bias, 1)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"NcULmeV5yUiE","executionInfo":{"status":"ok","timestamp":1770632848742,"user_tz":-540,"elapsed":15,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Details of Learning (Section 5)\n","# weight decay: 학습 오류 감소\n","model = AlexNet().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(\n","    params=model.parameters(),\n","    lr=0.01,\n","    momentum=0.9,\n","    weight_decay=0.0005\n",")\n","\n","lr_scheduler = optim.lr_scheduler.StepLR(\n","    optimizer=optimizer,\n","    step_size=30,\n","    gamma=0.1\n",")\n","\n","summary(model, input_size=(3, 227, 227), batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwscap5r7CUE","executionInfo":{"status":"ok","timestamp":1770640253344,"user_tz":-540,"elapsed":1378,"user":{"displayName":"오병직","userId":"04063980640589832756"}},"outputId":"8adafacc-c9ab-46fc-ebda-74e191387760"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [128, 96, 55, 55]          34,944\n","              ReLU-2          [128, 96, 55, 55]               0\n"," LocalResponseNorm-3          [128, 96, 55, 55]               0\n","         MaxPool2d-4          [128, 96, 27, 27]               0\n","            Conv2d-5         [128, 256, 27, 27]         614,656\n","              ReLU-6         [128, 256, 27, 27]               0\n"," LocalResponseNorm-7         [128, 256, 27, 27]               0\n","         MaxPool2d-8         [128, 256, 13, 13]               0\n","            Conv2d-9         [128, 384, 13, 13]         885,120\n","             ReLU-10         [128, 384, 13, 13]               0\n","           Conv2d-11         [128, 384, 13, 13]       1,327,488\n","             ReLU-12         [128, 384, 13, 13]               0\n","           Conv2d-13         [128, 256, 13, 13]         884,992\n","             ReLU-14         [128, 256, 13, 13]               0\n","        MaxPool2d-15           [128, 256, 6, 6]               0\n","          Dropout-16                [128, 9216]               0\n","           Linear-17                [128, 4096]      37,752,832\n","             ReLU-18                [128, 4096]               0\n","          Dropout-19                [128, 4096]               0\n","           Linear-20                [128, 4096]      16,781,312\n","             ReLU-21                [128, 4096]               0\n","           Linear-22                [128, 1000]       4,097,000\n","================================================================\n","Total params: 62,378,344\n","Trainable params: 62,378,344\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 75.48\n","Forward/backward pass size (MB): 1885.10\n","Params size (MB): 237.95\n","Estimated Total Size (MB): 2198.54\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# Data Augmentation (Section 4.1) - 과적합 방지\n","# mean substraction only, PCA color augmentation, 10 crop test 구현 X\n","TRAIN_DIR = ''\n","VAL_DIR = ''\n","TEST_DIR = ''\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.RandomCrop(227),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","\n","train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n","\n","train_loader = data.DataLoader(\n","    train_dataset,\n","    batch_size=128,\n","    shuffle=True,\n","    num_workers=8,\n","    pin_memory=True\n",")\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(227),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","\n","val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transform)\n","\n","val_loader = data.DataLoader(\n","    val_dataset,\n","    batch_size=128,\n","    shuffle=False,\n","    num_workers=8,\n","    pin_memory=True\n",")\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(227),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","\n","test_dataset = datasets.ImageFolder(TEST_DIR, transform=test_transform)\n","\n","test_loader = data.DataLoader(\n","    test_dataset,\n","    batch_size=128,\n","    shuffle=False,\n","    num_workers=8,\n","    pin_memory=True\n",")"],"metadata":{"id":"QQ-U_tRuJ5O1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Epoch (Section 5) - Roughly 90\n","best_acc = 0\n","for epoch in range(90):\n","    model.train()\n","\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for img, cls in train_loader:\n","        img, cls = img.to(device), cls.to(device)\n","\n","        output = model(img)\n","        loss = criterion(output, cls)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * img.size(0)\n","        _, preds = torch.max(output, 1)\n","        correct += (preds == cls).sum().item()\n","        total += cls.size(0)\n","\n","    train_loss /= total\n","    train_acc = correct / total\n","\n","    model.eval()\n","\n","    val_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for img, cls in val_loader:\n","            img, cls = img.to(device), cls.to(device)\n","\n","            output = model(img)\n","            loss = criterion(output, cls)\n","\n","            val_loss += loss.item() * img.size(0)\n","            _, preds = torch.max(output, 1)\n","            correct += (preds == cls).sum().item()\n","            total += cls.size(0)\n","\n","    val_loss /= total\n","    val_acc = correct / total\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch: {epoch + 1}/90 - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - Val Loss {val_loss:.4f} - Val Acc {val_acc:.4f}')\n","\n","    if val_acc > best_acc:\n","        best_acc = val_acc\n","        torch.save(model.state_dict(), \"best_alexnet.pth\")\n","        print(\"Best Model Updated\")\n","\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'best_acc': best_acc\n","    }, \"alexnet_checkpoint.pth\")\n","\n","    lr_scheduler.step()"],"metadata":{"id":"s6tedAWdNKoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"best_alexnet.pth\"))\n","model.to(device)\n","\n","model.eval()\n","\n","test_loss = 0\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for img, cls in test_loader:\n","        img, cls = img.to(device), cls.to(device)\n","\n","        output = model(img)\n","        loss = criterion(output, cls)\n","\n","        test_loss += loss.item() * img.size(0)\n","        _, preds = torch.max(output, 1)\n","        correct += (preds == cls).sum().item()\n","        total += cls.size(0)\n","\n","test_loss /= total\n","test_acc = correct / total\n","\n","print(f'Test Loss {test_loss:.4f} - Test Acc {test_acc:.4f}')"],"metadata":{"id":"X37RLyCEWNOl"},"execution_count":null,"outputs":[]}]}